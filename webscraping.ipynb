{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Digital Futures](https://github.com/digital-futures-academy/DataScienceMasterResources/blob/main/Resources/datascience-notebook-header.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the Project Environment\n",
    "\n",
    "Ultimately, the Python code written here will be extracted to scripts for execution in an automated pipeline.  To facilitate this, there is a need to set up a project environment that will allow for the execution of the code in a controlled and reproducible environment.\n",
    "\n",
    "In the initial stages of the activities, the packages needed are `requests` and `pytest`.  The `requests` package is used to make HTTP requests to the API, while `pytest` is used for testing the code we also need *BeautifulSoup* (package name `beautifulsoup4`.  In later activities, you may need to install additional packages.  To do this, add the packages to the `pip install` command below and re-run the cell.\n",
    "\n",
    "> **Remember:** The goal is to create a set of code cells that can be extracted to separate scripts for execution in an automated pipeline.  Therefore, the code should be kept in 3 distinct cells:\n",
    "> \n",
    "> - **Shell Commands**:  Used to set up the project environment\n",
    "> \n",
    "> - **Python Tests**: Used to test the Python production scripts both now and as part of the automated pipeline\n",
    "> \n",
    "> - **Python Production Code**: The Python code that will be extracted to a script to execute during the pipeline\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment Setup Scripts\n",
    "\n",
    "If you are running this notebook after cloning and have not set up your environment to run shell commands, you will need to run the following commands in your terminal to set up the environment.\n",
    "\n",
    "> **NOTE:**  These commands need to be executed in the terminal.  \n",
    ">\n",
    "> Open a terminal at the root of your project before executing these commands\n",
    "> \n",
    "> Until your environment is set up, Jupyter Notebooks will not be able to run **shell** scripts.\n",
    "\n",
    "```sh\n",
    "# Create a virtual environment (add the command below)\n",
    "python3 -m venv .venv # Note: This command could also be python -m venv .venv # python3 and python are a symlink to the python version installed on your system\n",
    "\n",
    "# Activate the virtual environment \n",
    "source .venv/bin/activate\n",
    "\n",
    "# Install required package to execute shell commands from Jupyter Notebook\n",
    "pip install ipykernel               ## OR \n",
    "pip install -r requirements.txt     ## IF there is already a requirements.txt file CONTAINING ipykenrnel in the project\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: pytest in c:\\users\\afzal\\desktop\\digital futures\\python\\web-scraping-sen-mo\\.venv\\lib\\site-packages (8.3.3)\n",
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests)\n",
      "  Using cached charset_normalizer-3.4.0-cp313-cp313-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Using cached urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\afzal\\desktop\\digital futures\\python\\web-scraping-sen-mo\\.venv\\lib\\site-packages (from pytest) (2.0.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\afzal\\desktop\\digital futures\\python\\web-scraping-sen-mo\\.venv\\lib\\site-packages (from pytest) (24.2)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in c:\\users\\afzal\\desktop\\digital futures\\python\\web-scraping-sen-mo\\.venv\\lib\\site-packages (from pytest) (1.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\afzal\\desktop\\digital futures\\python\\web-scraping-sen-mo\\.venv\\lib\\site-packages (from pytest) (0.4.6)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4)\n",
      "  Using cached soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Using cached charset_normalizer-3.4.0-cp313-cp313-win_amd64.whl (102 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Installing collected packages: urllib3, soupsieve, idna, charset-normalizer, certifi, requests, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.12.3 certifi-2024.8.30 charset-normalizer-3.4.0 idna-3.10 requests-2.32.3 soupsieve-2.6 urllib3-2.2.3\n"
     ]
    }
   ],
   "source": [
    "# Install the necessary packages\n",
    "!pip install requests pytest beautifulsoup4\n",
    "\n",
    "# Create a requirements.txt file\n",
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** \n",
    "> The `!` at the beginning of the lines is a special character in Jupyter Notebooks that allows you to run shell commands from the notebook.  \n",
    "> These will need to be removed from any commands that are to be exported to a `.sh` shell script file for the pipeline.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Tests\n",
    "\n",
    "Develop any tests for functions in separate cells below.  The first has been provided for you as an example, add others as necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test `request_to_scrape`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test request_to_scrape\n",
    "import pytest\n",
    "from unittest.mock import patch\n",
    "from requests.exceptions import Timeout, RequestException\n",
    "\n",
    "def test_request_to_scrape_makes_correct_request():\n",
    "  # Arrange\n",
    "  url = 'http://books.toscrape.com/'\n",
    "\n",
    "  with patch('requests.get') as mock_get:\n",
    "        mock_get.return_value.status_code = 200\n",
    "        # Act\n",
    "        request_to_scrape(url)\n",
    "\n",
    "        # Assert\n",
    "        mock_get.assert_called_with(url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the tests\n",
    "\n",
    "Run the cell containing the `ipytest.run()` command to execute the tests.  The tests should all fail until you have written the production code.\n",
    "\n",
    "Don't forget to run the installation and initialisation cell too on the first time you run the tests!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# Python Production Code\n",
    "\n",
    "\n",
    "Develop any functions for use as production code in separate cells below. The first has been provided as an example under the Production Constants, add others as necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRODUCTION CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRODUCTION CONSTANTS\n",
    "\n",
    "# Constants for status messages\n",
    "STATUS_SUCCESS = \"success\"\n",
    "STATUS_ERROR = \"error\"\n",
    "ERROR_NOT_HTML = \"The response is not HTML\"\n",
    "ERROR_REQUEST_FAILED = \"Request failed for URL\"\n",
    "ERROR_UNEXPECTED = \"Unexpected error for URL\"\n",
    "\n",
    "# HTML Parser\n",
    "HTML_PARSER = \"html.parser\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `request_to_scrape` Production Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# request_to_scrape Production Code\n",
    "def request_to_scrape(url):\n",
    "  return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Python Execution Code\n",
    "\n",
    "Develop any code to call the developed functions below.  Add additional cells so you don't need to re-run all of the code when you develop further scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Execution Code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter Notebook Test and Linting Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run `pytest` scripts in a Jupyter Notebook cell, we need to install the `ipytest` package.  This package is NOT required for a pipeline and therefore it can be removed from the `requirements.txt` file before adding the production code to the pipeline.\n",
    "\n",
    "To run linting, we need to install 2 packages `nbqa` and `flake8`.  We will make sure that `flake8` is included in the `requirements.txt` file when constructing the pipeline so that we can lint as part of the pipeline tests.\n",
    "\n",
    "Run the following cell to install the `ipytest`, `nbqa` and `flake8` packages and a coverage package to help determine if all of your production code is executed during the tests!\n",
    "\n",
    "This cell only needs to be run once (or after restarting the notebook kernel) to set up the environment for testing and linting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipytest in c:\\users\\afzal\\desktop\\digital futures\\python\\web-scraping-sen-mo\\.venv\\lib\\site-packages (0.14.2)\n",
      "Requirement already satisfied: nbqa in c:\\users\\afzal\\desktop\\digital futures\\python\\web-scraping-sen-mo\\.venv\\lib\\site-packages (1.9.1)\n",
      "Collecting flake8\n",
      "  Using cached flake8-7.1.1-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: ipython in c:\\users\\afzal\\desktop\\digital futures\\python\\web-scraping-sen-mo\\.venv\\lib\\site-packages (from ipytest) (8.29.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\afzal\\desktop\\digital futures\\python\\web-scraping-sen-mo\\.venv\\lib\\site-packages (from ipytest) (24.2)\n",
      "Requirement already satisfied: pytest>=5.4 in c:\\users\\afzal\\desktop\\digital futures\\python\\web-scraping-sen-mo\\.venv\\lib\\site-packages (from ipytest) (8.3.3)\n",
      "Requirement already satisfied: autopep8>=1.5 in c:\\users\\afzal\\desktop\\digital futures\\python\\web-scraping-sen-mo\\.venv\\lib\\site-packages (from nbqa) (2.3.1)\n",
      "Requirement already satisfied: tokenize-rt>=3.2.0 in c:\\users\\afzal\\desktop\\digital futures\\python\\web-scraping-sen-mo\\.venv\\lib\\site-packages (from nbqa) (6.1.0)\n",
      "Requirement already satisfied: tomli in c:\\users\\afzal\\desktop\\digital futures\\python\\web-scraping-sen-mo\\.venv\\lib\\site-packages (from nbqa) (2.1.0)\n",
      "Collecting mccabe<0.8.0,>=0.7.0 (from flake8)\n",
      "  Using cached mccabe-0.7.0-py2.py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: pycodestyle<2.13.0,>=2.12.0 in c:\\users\\afzal\\desktop\\digital futures\\python\\web-scraping-sen-mo\\.venv\\lib\\site-packages (from flake8) (2.12.1)\n",
      "Collecting pyflakes<3.3.0,>=3.2.0 (from flake8)\n",
      "  Using cached pyflakes-3.2.0-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: decorator in c:\\users\\afzal\\desktop\\digital futures\\python\\web-scraping-sen-mo\\.venv\\lib\\site-packages (from ipython->ipytest) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\afzal\\desktop\\digital futures\\python\\web-scraping-sen-mo\\.venv\\lib\\site-packages (from ipython->ipytest) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\afzal\\desktop\\digital futures\\python\\web-scraping-sen-mo\\.venv\\lib\\site-packages (from ipython->ipytest) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\afzal\\desktop\\digital futures\\python\\web-scraping-sen-mo\\.venv\\lib\\site-packages (from ipython->ipytest) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\afzal\\desktop\\digital futures\\python\\web-scraping-sen-mo\\.venv\\lib\\site-packages (from ipython->ipytest) (2.18.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\afzal\\desktop\\digital futures\\python\\web-scraping-sen-mo\\.venv\\lib\\site-packages (from ipython->ipytest) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\afzal\\desktop\\digital futures\\python\\web-scraping-sen-mo\\.venv\\lib\\site-packages (from ipython->ipytest) (5.14.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\afzal\\desktop\\digital futures\\python\\web-scraping-sen-mo\\.venv\\lib\\site-packages (from ipython->ipytest) (0.4.6)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\afzal\\desktop\\digital futures\\python\\web-scraping-sen-mo\\.venv\\lib\\site-packages (from pytest>=5.4->ipytest) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in c:\\users\\afzal\\desktop\\digital futures\\python\\web-scraping-sen-mo\\.venv\\lib\\site-packages (from pytest>=5.4->ipytest) (1.5.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\afzal\\desktop\\digital futures\\python\\web-scraping-sen-mo\\.venv\\lib\\site-packages (from jedi>=0.16->ipython->ipytest) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\afzal\\desktop\\digital futures\\python\\web-scraping-sen-mo\\.venv\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython->ipytest) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\afzal\\desktop\\digital futures\\python\\web-scraping-sen-mo\\.venv\\lib\\site-packages (from stack-data->ipython->ipytest) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\afzal\\desktop\\digital futures\\python\\web-scraping-sen-mo\\.venv\\lib\\site-packages (from stack-data->ipython->ipytest) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\afzal\\desktop\\digital futures\\python\\web-scraping-sen-mo\\.venv\\lib\\site-packages (from stack-data->ipython->ipytest) (0.2.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\afzal\\desktop\\digital futures\\python\\web-scraping-sen-mo\\.venv\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython->ipytest) (1.16.0)\n",
      "Using cached flake8-7.1.1-py2.py3-none-any.whl (57 kB)\n",
      "Using cached mccabe-0.7.0-py2.py3-none-any.whl (7.3 kB)\n",
      "Using cached pyflakes-3.2.0-py2.py3-none-any.whl (62 kB)\n",
      "Installing collected packages: pyflakes, mccabe, flake8\n",
      "Successfully installed flake8-7.1.1 mccabe-0.7.0 pyflakes-3.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install the `ipytest`, `nbqa` and `flake8` packages\n",
    "!pip install ipytest nbqa flake8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up `ipytest` to execute `pytest` scripts in Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure ipytest for Jupyter Notebook\n",
    "\n",
    "import ipytest\n",
    "ipytest.autoconfig(rewrite_asserts=True, magics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a *config* file for `flake8`\n",
    "\n",
    "Run this script to create a file in your project root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Create a config file and ignore some flake8 rules\n",
    "!echo \"[flake8]\" > .flake8\n",
    "!echo \"ignore = E402, W291, F811\" >> .flake8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute the tests and linting in the Jupyter Notebook\n",
    "\n",
    "Run the following cell ***EVERY TIME*** you want to run the tests and linting that you have written in the *Python Tests* cell above.\n",
    "\n",
    ">**Note:**\n",
    ">\n",
    "> This entire section does not need to be part of any pipeline scripts.  \n",
    "> It is only required for the Jupyter Notebook environment during development.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m======================================= test session starts =======================================\u001b[0m\n",
      "platform win32 -- Python 3.13.0, pytest-8.3.3, pluggy-1.5.0 -- c:\\Users\\afzal\\Desktop\\Digital Futures\\Python\\web-scraping-sen-mo\\.venv\\Scripts\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: c:\\Users\\afzal\\Desktop\\Digital Futures\\Python\\web-scraping-sen-mo\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "t_aace512d50c64b84ba6ec5fc4778fc78.py::test_request_to_scrape_makes_correct_request \u001b[31mFAILED\u001b[0m\n",
      "\n",
      "============================================ FAILURES =============================================\n",
      "\u001b[31m\u001b[1m__________________________ test_request_to_scrape_makes_correct_request ___________________________\u001b[0m\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m \u001b[92mtest_request_to_scrape_makes_correct_request\u001b[39;49;00m():\u001b[90m\u001b[39;49;00m\n",
      "      \u001b[90m# Arrange\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "      url = \u001b[33m'\u001b[39;49;00m\u001b[33mhttp://books.toscrape.com/\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "      \u001b[94mwith\u001b[39;49;00m patch(\u001b[33m'\u001b[39;49;00m\u001b[33mrequests.get\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[94mas\u001b[39;49;00m mock_get:\u001b[90m\u001b[39;49;00m\n",
      "            mock_get.return_value.status_code = \u001b[94m200\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Act\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            request_to_scrape(url)\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m\u001b[39;49;00m\n",
      "            \u001b[90m# Assert\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      ">           mock_get.assert_called_with(url)\u001b[90m\u001b[39;49;00m\n",
      "\n",
      "\u001b[1m\u001b[31mC:\\Users\\afzal\\AppData\\Local\\Temp\\ipykernel_13076\\3743736896.py\u001b[0m:16: \n",
      "_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _\n",
      "\n",
      "self = <MagicMock name='get' id='1887637919392'>, args = ('http://books.toscrape.com/',)\n",
      "kwargs = {}, expected = \"get('http://books.toscrape.com/')\", actual = 'not called.'\n",
      "error_message = \"expected call not found.\\nExpected: get('http://books.toscrape.com/')\\n  Actual: not called.\"\n",
      "\n",
      "    \u001b[0m\u001b[94mdef\u001b[39;49;00m \u001b[92massert_called_with\u001b[39;49;00m(\u001b[96mself\u001b[39;49;00m, /, *args, **kwargs):\u001b[90m\u001b[39;49;00m\n",
      "    \u001b[90m    \u001b[39;49;00m\u001b[33m\"\"\"assert that the last call was made with the specified arguments.\u001b[39;49;00m\n",
      "    \u001b[33m\u001b[39;49;00m\n",
      "    \u001b[33m    Raises an AssertionError if the args and keyword args passed in are\u001b[39;49;00m\n",
      "    \u001b[33m    different to the last call to the mock.\"\"\"\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "        \u001b[94mif\u001b[39;49;00m \u001b[96mself\u001b[39;49;00m.call_args \u001b[95mis\u001b[39;49;00m \u001b[94mNone\u001b[39;49;00m:\u001b[90m\u001b[39;49;00m\n",
      "            expected = \u001b[96mself\u001b[39;49;00m._format_mock_call_signature(args, kwargs)\u001b[90m\u001b[39;49;00m\n",
      "            actual = \u001b[33m'\u001b[39;49;00m\u001b[33mnot called.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "            error_message = (\u001b[33m'\u001b[39;49;00m\u001b[33mexpected call not found.\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33mExpected: \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m  Actual: \u001b[39;49;00m\u001b[33m%s\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[90m\u001b[39;49;00m\n",
      "                    % (expected, actual))\u001b[90m\u001b[39;49;00m\n",
      ">           \u001b[94mraise\u001b[39;49;00m \u001b[96mAssertionError\u001b[39;49;00m(error_message)\u001b[90m\u001b[39;49;00m\n",
      "\u001b[1m\u001b[31mE           AssertionError: expected call not found.\u001b[0m\n",
      "\u001b[1m\u001b[31mE           Expected: get('http://books.toscrape.com/')\u001b[0m\n",
      "\u001b[1m\u001b[31mE             Actual: not called.\u001b[0m\n",
      "\n",
      "\u001b[1m\u001b[31m..\\..\\..\\..\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\unittest\\mock.py\u001b[0m:968: AssertionError\n",
      "\u001b[36m\u001b[1m===================================== short test summary info =====================================\u001b[0m\n",
      "\u001b[31mFAILED\u001b[0m t_aace512d50c64b84ba6ec5fc4778fc78.py::\u001b[1mtest_request_to_scrape_makes_correct_request\u001b[0m - AssertionError: expected call not found.\n",
      "\u001b[31m======================================== \u001b[31m\u001b[1m1 failed\u001b[0m\u001b[31m in 0.42s\u001b[0m\u001b[31m ========================================\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.TESTS_FAILED: 1>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the tests\n",
    "ipytest.run(\"-vv\", \"-ss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the linter\n",
    "\n",
    "Run this script each time you want to lint your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "webscraping.ipynb:cell_2:3: [E114] indentation is not a multiple of 4 (comment)\n",
      "  # Arrange\n",
      "  ^\n",
      "webscraping.ipynb:cell_2:4: [E111] indentation is not a multiple of 4\n",
      "  url = 'http://books.toscrape.com/'\n",
      "  ^\n",
      "webscraping.ipynb:cell_2:6: [E111] indentation is not a multiple of 4\n",
      "  with patch('requests.get') as mock_get:\n",
      "  ^\n",
      "webscraping.ipynb:cell_2:6: [F821] undefined name 'patch'\n",
      "  with patch('requests.get') as mock_get:\n",
      "       ^\n",
      "webscraping.ipynb:cell_2:7: [E111] indentation is not a multiple of 4\n",
      "          mock_get.return_value.status_code = 200\n",
      "          ^\n",
      "webscraping.ipynb:cell_2:7: [E117] over-indented\n",
      "          mock_get.return_value.status_code = 200\n",
      "          ^\n",
      "webscraping.ipynb:cell_2:8: [E114] indentation is not a multiple of 4 (comment)\n",
      "  # Act\n",
      "  ^\n",
      "webscraping.ipynb:cell_2:9: [F821] undefined name 'request_to_scrape'\n",
      "  request_to_scrape(url)\n",
      "  ^\n",
      "webscraping.ipynb:cell_2:9: [E111] indentation is not a multiple of 4\n",
      "  request_to_scrape(url)\n",
      "  ^\n",
      "webscraping.ipynb:cell_2:10: [E114] indentation is not a multiple of 4 (comment)\n",
      "  # Assert\n",
      "  ^\n",
      "webscraping.ipynb:cell_7:3: [E402] module level import not at top of file\n",
      "import ipytest\n",
      "^\n"
     ]
    }
   ],
   "source": [
    "# Run the linter\n",
    "!nbqa flake8 --show-source --format=pylint webscraping.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
